{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05c55ca5",
   "metadata": {},
   "source": [
    "DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e9d1843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "#READ data frame \n",
    "df_input = pd.read_csv(\"adult.input\",header=None)\n",
    "df_test = pd.read_csv(\"adult.test\",header=None)\n",
    "\n",
    "df_input\n",
    "\n",
    "# #add the column names\n",
    "df_input.columns = ['age','type_employer','fnlwgt','education','education_num','marital','occupation',\n",
    "             'relationship','race','sex','capital_gain','capital_loss','hr_per_week','country',\n",
    "             'income']\n",
    "df_test.columns = ['age','type_employer','fnlwgt','education','education_num','marital','occupation',\n",
    "             'relationship','race','sex','capital_gain','capital_loss','hr_per_week','country',\n",
    "             'income']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e0a2dc",
   "metadata": {},
   "source": [
    "INPUT DATA PREPROCCESING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e587a14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#remove instances with the missing values \"?\" marker\n",
    "df_input = df_input.loc[df_input[\"age\"] != \"?\"]\n",
    "df_input = df_input.loc[df_input[\"type_employer\"] != \"?\"]\n",
    "df_input = df_input.loc[df_input[\"fnlwgt\"] != \"?\"]\n",
    "df_input = df_input.loc[df_input[\"education\"] != \"?\"]\n",
    "df_input = df_input.loc[df_input[\"education_num\"] != \"?\"]\n",
    "df_input = df_input.loc[df_input[\"marital\"] != \"?\"]\n",
    "df_input = df_input.loc[df_input[\"occupation\"] != \"?\"]\n",
    "df_input = df_input.loc[df_input[\"relationship\"] != \"?\"]\n",
    "df_input = df_input.loc[df_input[\"race\"] != \"?\"]\n",
    "df_input = df_input.loc[df_input[\"sex\"] != \"?\"]\n",
    "df_input = df_input.loc[df_input[\"capital_gain\"] != \"?\"]\n",
    "df_input = df_input.loc[df_input[\"capital_loss\"] != \"?\"]\n",
    "df_input = df_input.loc[df_input[\"hr_per_week\"] != \"?\"]\n",
    "df_input = df_input.loc[df_input[\"country\"] != \"?\"]\n",
    "df_input = df_input.loc[df_input[\"income\"] != \"?\"]\n",
    "\n",
    "#df_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a6d7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove attributes fnlwgt,education,relationship\n",
    "#NOTE: DROPPED education_num because it was irrelevant when education atribute is prunned. \\\n",
    "#It also reduces the possibility of overfitting.\n",
    "\n",
    "df_input.drop(columns=[\"fnlwgt\",\"education\",\"relationship\",\"education_num\"],inplace=True)\n",
    "\n",
    "#df_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7be807",
   "metadata": {},
   "outputs": [],
   "source": [
    "#binarization of capital gain, capital loss, and native country attributes\n",
    "\n",
    "df_input.loc[df_input[\"capital_gain\"] == 0,\"capital_gain\"] = 0\n",
    "df_input.loc[df_input[\"capital_gain\"] > 0,\"capital_gain\"] = 1\n",
    "\n",
    "df_input.loc[df_input[\"capital_loss\"] == 0,\"capital_loss\"] = 0\n",
    "df_input.loc[df_input[\"capital_loss\"] > 0,\"capital_loss\"] = 1\n",
    "\n",
    "#TESTING\n",
    "# poor_jaja = df_input.loc[df_input[\"capital_gain\"] == 0]\n",
    "# poor_jaja\n",
    "# rich_jaja = df_input.loc[df_input[\"capital_loss\"] == 1]\n",
    "# rich_jaja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2675ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input[\"country\"] = np.where(df_input[\"country\"] == \"United-States\", 1, 0)\n",
    "\n",
    "#df_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25776e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discretization of continuous attributes [age,hours_per_week]\n",
    "df_input[\"young\"] = np.where(df_input.age.astype(int) <= 25, 1, 0)\n",
    "df_input[\"adult\"] = np.where((df_input.age.astype(int) >= 26) & (df_input.age.astype(int) <= 45), 1, 0)\n",
    "df_input[\"senior\"] = np.where((df_input.age.astype(int) >= 46) & (df_input.age.astype(int) <= 65), 1, 0)\n",
    "df_input[\"old\"] = np.where((df_input.age.astype(int) >= 66) & (df_input.age.astype(int) <= 90), 1, 0)\n",
    "\n",
    "df_input.drop(columns=[\"age\"],inplace=True)\n",
    "#df_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816075ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input[\"part_time\"] = np.where(df_input.hr_per_week.astype(int) < 40, 1, 0)\n",
    "df_input[\"full_time\"] = np.where(df_input.hr_per_week.astype(int) == 40, 1, 0)\n",
    "df_input[\"over_time\"] = np.where(df_input.hr_per_week.astype(int) > 40, 1, 0)\n",
    "\n",
    "df_input.drop(columns=[\"hr_per_week\"],inplace=True)\n",
    "\n",
    "# df_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25ff2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge values and creation of new binary assymetric attributes, WORKING CLASS\n",
    "# [Fed,local,stat]-> gov\n",
    "# [w/o pay, never worked] -> not_working\n",
    "# [Private] -> private\n",
    "# [Self-inc,self-not-inc] -> self_employed\n",
    "\n",
    "df_input[\"gov\"] = np.where( ((df_input[\"type_employer\"] == \"Federal-gov\") | (df_input[\"type_employer\"] == \"Local-gov\") | (df_input[\"type_employer\"] == \"State-gov\")), 1, 0)\n",
    "\n",
    "df_input[\"not_working\"] = np.where( ((df_input[\"type_employer\"] == \"Without-pay\") | (df_input[\"type_employer\"] == \"Never-worked\")), 1, 0)\n",
    "\n",
    "df_input[\"private\"] = np.where( (df_input[\"type_employer\"] == \"Private\"), 1, 0)\n",
    "\n",
    "df_input[\"self_employed\"] = np.where( ((df_input[\"type_employer\"] == \"Self-emp-inc\") | (df_input[\"type_employer\"] == \"Self-emp-not-inc\")), 1, 0)\n",
    "\n",
    "df_input.drop(columns=[\"type_employer\"],inplace=True)\n",
    "\n",
    "# df_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762ac5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge values and creation of new binary assymetric attributes, MARITAL STATUS\n",
    "# [Married-AF-spouse, Married-civ-spouse)]-> married\n",
    "# [w/o pay, never worked] -> not_working\n",
    "# [Never-married] -> never_married\n",
    "# [Married-spouse-absent, Separated, Divorced, Widowed] -> not-married\n",
    "\n",
    "df_input[\"married\"] = np.where( ((df_input[\"marital\"] == \"Married-AF-spouse\") | (df_input[\"marital\"] == \"Married-civ-spouse\") ), 1, 0)\n",
    "\n",
    "df_input[\"never_married\"] = np.where( (df_input[\"marital\"] == \"Never-married\" ), 1, 0)\n",
    "\n",
    "df_input[\"not_married\"] = np.where( ((df_input[\"marital\"] == \"Married-spouse-absent\") | (df_input[\"marital\"] == \"Separated\") \n",
    "| (df_input[\"marital\"] == \"Divorced\") | (df_input[\"marital\"] == \"Widowed\")), 1, 0)\n",
    "\n",
    "df_input.drop(columns=[\"marital\"],inplace=True)\n",
    "\n",
    "# df_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aed58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge values and creation of new binary assymetric attributes, OCCUPATION\n",
    "# [Exec-managerial]-> exec_managerial\n",
    "# [Prof-specialty] -> prof_specialty\n",
    "# [Tech-support, Adm-clerical, Priv-house-serv, Protective-serv, Armed-Forces, Other-service] -> other\n",
    "# [Craft-repair, Farming-fishing, Handlers-cleaners, Machine-op-inspct, Transport-moving] -> manual_work\n",
    "# [Sales] -> sales\n",
    "\n",
    "df_input[\"exec_managerial\"] = np.where( ((df_input[\"occupation\"] == \"Exec-managerial\")), 1, 0)\n",
    "\n",
    "df_input[\"prof_specialty\"] = np.where( ((df_input[\"occupation\"] == \"Prof-specialty\")), 1, 0)\n",
    "\n",
    "df_input[\"other\"] = np.where( ((df_input[\"occupation\"] == \"Tech-support\") | (df_input[\"occupation\"] == \"Adm-clerical\")\n",
    "| (df_input[\"occupation\"] == \"Priv-house-serv\") | (df_input[\"occupation\"] == \"Protective-serv\") \n",
    "| (df_input[\"occupation\"] == \"Armed-Forces\")| (df_input[\"occupation\"] == \"Other-service\") ), 1, 0)\n",
    "\n",
    "df_input[\"manual_work\"] = np.where( ((df_input[\"occupation\"] == \"Craft-repair\") | (df_input[\"occupation\"] == \"Farming-fishing\") \n",
    "| (df_input[\"occupation\"] == \"Handlers-cleaners\") | (df_input[\"occupation\"] == \"Machine-op-inspct\") | (df_input[\"occupation\"] == \"Transport-moving\")), 1, 0)\n",
    "\n",
    "df_input[\"sales\"] = np.where( ((df_input[\"occupation\"] == \"Sales\")), 1, 0)\n",
    "df_input.drop(columns=[\"occupation\"],inplace=True)\n",
    "\n",
    "# TESTING\n",
    "# sas = df_input.loc[(df_input[\"exec_managerial\"] == 0) & (df_input[\"prof_specialty\"] == 0)  & (df_input[\"other\"] == 0) & (df_input[\"manual_work\"] == 0) & \n",
    "# (df_input[\"sales\"] == 0)]\n",
    "# sas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9916dd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BINARIZATION OF EXTRA ATTRIBUTES [race,sex,income]\n",
    "\n",
    "#Where 1 means >50k , and 0 otherwise\n",
    "df_input[\"income\"] = np.where( ((df_input[\"income\"] == \">50K\")), 1, 0)\n",
    "\n",
    "#creation of assymetric attributes for gender \n",
    "df_input[\"male\"] = np.where( ((df_input[\"sex\"] == \"Male\")), 1, 0)\n",
    "df_input[\"female\"] = np.where( ((df_input[\"sex\"] == \"Female\")), 1, 0)\n",
    "df_input.drop(columns=[\"sex\"],inplace=True)\n",
    "\n",
    "#creation of assymetric attributes for race\n",
    "#print(df_input['race'].unique()) ---> ['White' 'Asian-Pac-Islander' 'Black' 'Other' 'Amer-Indian-Eskimo']\n",
    "df_input[\"white\"] = np.where( ((df_input[\"race\"] == \"White\")), 1, 0)\n",
    "df_input[\"asian\"] = np.where( ((df_input[\"race\"] == \"Asian-Pac-Islander\")), 1, 0)\n",
    "df_input[\"black\"] = np.where( ((df_input[\"race\"] == \"Black\")), 1, 0)\n",
    "df_input[\"other\"] = np.where( ((df_input[\"race\"] == \"Other\")), 1, 0)\n",
    "df_input[\"amerindian\"] = np.where( ((df_input[\"race\"] == \"Amer-Indian-Eskimo\")), 1, 0)\n",
    "df_input.drop(columns=[\"race\"],inplace=True)\n",
    "\n",
    "# TESTING\n",
    "# sas = df_input.loc[(df_input[\"white\"] ==1) & (df_input[\"asian\"] ==1) & (df_input[\"black\"] ==1) & (df_input[\"other\"] ==1) & (df_input[\"amerindian\"] ==1)]\n",
    "# sas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6b1738",
   "metadata": {},
   "source": [
    "TEST DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b228e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Dropping irrelevent attributes\n",
    "df_test.drop(columns=[\"fnlwgt\",\"education\",\"relationship\",\"education_num\",\"income\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff06535",
   "metadata": {},
   "outputs": [],
   "source": [
    "#binarization of capital gain, capital loss, and native country attributes\n",
    "\n",
    "df_test.loc[df_test[\"capital_gain\"] == 0,\"capital_gain\"] = 0\n",
    "df_test.loc[df_test[\"capital_gain\"] > 0,\"capital_gain\"] = 1\n",
    "\n",
    "df_test.loc[df_test[\"capital_loss\"] == 0,\"capital_loss\"] = 0\n",
    "df_test.loc[df_test[\"capital_loss\"] > 0,\"capital_loss\"] = 1\n",
    "\n",
    "#TESTING\n",
    "# poor_jaja = df_test.loc[df_test[\"capital_gain\"] == 0] #896\n",
    "# poor_jaja\n",
    "# rich_jaja = df_test.loc[df_test[\"capital_gain\"] == 1] #104\n",
    "# rich_jaja\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef04abf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"country\"] = np.where(df_test[\"country\"] == \"United-States\", 1, 0)\n",
    "# df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb27ee82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discretization of continuous attributes [age,hours_per_week]\n",
    "df_test[\"young\"] = np.where(df_test.age.astype(int) <= 25, 1, 0)\n",
    "df_test[\"adult\"] = np.where((df_test.age.astype(int) >= 26) & (df_test.age.astype(int) <= 45), 1, 0)\n",
    "df_test[\"senior\"] = np.where((df_test.age.astype(int) >= 46) & (df_test.age.astype(int) <= 65), 1, 0)\n",
    "df_test[\"old\"] = np.where((df_test.age.astype(int) >= 66) & (df_test.age.astype(int) <= 90), 1, 0)\n",
    "\n",
    "df_test.drop(columns=[\"age\"],inplace=True)\n",
    "# df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dc584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"part_time\"] = np.where(df_test.hr_per_week.astype(int) < 40, 1, 0)\n",
    "df_test[\"full_time\"] = np.where(df_test.hr_per_week.astype(int) == 40, 1, 0)\n",
    "df_test[\"over_time\"] = np.where(df_test.hr_per_week.astype(int) > 40, 1, 0)\n",
    "\n",
    "df_test.drop(columns=[\"hr_per_week\"],inplace=True)\n",
    "\n",
    "# df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f181a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge values and creation of new binary assymetric attributes, WORKING CLASS\n",
    "# [Fed,local,stat]-> gov\n",
    "# [w/o pay, never worked] -> not_working\n",
    "# [Private] -> private\n",
    "# [Self-inc,self-not-inc] -> self_employed\n",
    "\n",
    "df_test[\"gov\"] = np.where( ((df_test[\"type_employer\"] == \"Federal-gov\") | (df_test[\"type_employer\"] == \"Local-gov\") | (df_test[\"type_employer\"] == \"State-gov\")), 1, 0)\n",
    "\n",
    "df_test[\"not_working\"] = np.where( ((df_test[\"type_employer\"] == \"Without-pay\") | (df_test[\"type_employer\"] == \"Never-worked\")), 1, 0)\n",
    "\n",
    "df_test[\"private\"] = np.where( (df_test[\"type_employer\"] == \"Private\"), 1, 0)\n",
    "\n",
    "df_test[\"self_employed\"] = np.where( ((df_test[\"type_employer\"] == \"Self-emp-inc\") | (df_test[\"type_employer\"] == \"Self-emp-not-inc\")), 1, 0)\n",
    "\n",
    "df_test.drop(columns=[\"type_employer\"],inplace=True)\n",
    "\n",
    "# df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aee324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge values and creation of new binary assymetric attributes, MARITAL STATUS\n",
    "# [Married-AF-spouse, Married-civ-spouse)]-> married\n",
    "# [w/o pay, never worked] -> not_working\n",
    "# [Never-married] -> never_married\n",
    "# [Married-spouse-absent, Separated, Divorced, Widowed] -> not-married\n",
    "\n",
    "df_test[\"married\"] = np.where( ((df_test[\"marital\"] == \"Married-AF-spouse\") | (df_test[\"marital\"] == \"Married-civ-spouse\") ), 1, 0)\n",
    "\n",
    "df_test[\"never_married\"] = np.where( (df_test[\"marital\"] == \"Never-married\" ), 1, 0)\n",
    "\n",
    "df_test[\"not_married\"] = np.where( ((df_test[\"marital\"] == \"Married-spouse-absent\") | (df_test[\"marital\"] == \"Separated\") \n",
    "| (df_test[\"marital\"] == \"Divorced\") | (df_test[\"marital\"] == \"Widowed\")), 1, 0)\n",
    "\n",
    "df_test.drop(columns=[\"marital\"],inplace=True)\n",
    "\n",
    "# df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278108a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge values and creation of new binary assymetric attributes, OCCUPATION\n",
    "# [Exec-managerial]-> exec_managerial\n",
    "# [Prof-specialty] -> prof_specialty\n",
    "# [Tech-support, Adm-clerical, Priv-house-serv, Protective-serv, Armed-Forces, Other-service] -> other\n",
    "# [Craft-repair, Farming-fishing, Handlers-cleaners, Machine-op-inspct, Transport-moving] -> manual_work\n",
    "# [Sales] -> sales\n",
    "\n",
    "df_test[\"exec_managerial\"] = np.where( ((df_test[\"occupation\"] == \"Exec-managerial\")), 1, 0)\n",
    "\n",
    "df_test[\"prof_specialty\"] = np.where( ((df_test[\"occupation\"] == \"Prof-specialty\")), 1, 0)\n",
    "\n",
    "df_test[\"other\"] = np.where( ((df_test[\"occupation\"] == \"Tech-support\") | (df_test[\"occupation\"] == \"Adm-clerical\")\n",
    "| (df_test[\"occupation\"] == \"Priv-house-serv\") | (df_test[\"occupation\"] == \"Protective-serv\") \n",
    "| (df_test[\"occupation\"] == \"Armed-Forces\")| (df_test[\"occupation\"] == \"Other-service\") ), 1, 0)\n",
    "\n",
    "df_test[\"manual_work\"] = np.where( ((df_test[\"occupation\"] == \"Craft-repair\") | (df_test[\"occupation\"] == \"Farming-fishing\") \n",
    "| (df_test[\"occupation\"] == \"Handlers-cleaners\") | (df_test[\"occupation\"] == \"Machine-op-inspct\") | (df_test[\"occupation\"] == \"Transport-moving\")), 1, 0)\n",
    "\n",
    "df_test[\"sales\"] = np.where( ((df_test[\"occupation\"] == \"Sales\")), 1, 0)\n",
    "df_test.drop(columns=[\"occupation\"],inplace=True)\n",
    "\n",
    "# TESTING\n",
    "# sas = df_test.loc[(df_test[\"exec_managerial\"] == 0) & (df_test[\"prof_specialty\"] == 0)  & (df_test[\"other\"] == 0) & (df_test[\"manual_work\"] == 0) & \n",
    "# (df_test[\"sales\"] == 0)]\n",
    "# sas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a08a527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BINARIZATION OF EXTRA ATTRIBUTES [race,sex] \n",
    "\n",
    "#creation of assymetric attributes for gender \n",
    "df_test[\"male\"] = np.where( ((df_test[\"sex\"] == \"Male\")), 1, 0)\n",
    "df_test[\"female\"] = np.where( ((df_test[\"sex\"] == \"Female\")), 1, 0)\n",
    "df_test.drop(columns=[\"sex\"],inplace=True)\n",
    "\n",
    "#creation of assymetric attributes for race\n",
    "#print(df_test['race'].unique()) ---> ['White' 'Asian-Pac-Islander' 'Black' 'Other' 'Amer-Indian-Eskimo']\n",
    "df_test[\"white\"] = np.where( ((df_test[\"race\"] == \"White\")), 1, 0)\n",
    "df_test[\"asian\"] = np.where( ((df_test[\"race\"] == \"Asian-Pac-Islander\")), 1, 0)\n",
    "df_test[\"black\"] = np.where( ((df_test[\"race\"] == \"Black\")), 1, 0)\n",
    "df_test[\"other\"] = np.where( ((df_test[\"race\"] == \"Other\")), 1, 0)\n",
    "df_test[\"amerindian\"] = np.where( ((df_test[\"race\"] == \"Amer-Indian-Eskimo\")), 1, 0)\n",
    "df_test.drop(columns=[\"race\"],inplace=True)\n",
    "\n",
    "# TESTING\n",
    "# sas = df_test.loc[(df_test[\"white\"] ==1) & (df_test[\"asian\"] ==1) & (df_test[\"black\"] ==1) & (df_test[\"other\"] ==1) & (df_test[\"amerindian\"] ==1)]\n",
    "# sas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c31c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test, 28 columns because We dropped the income columns as it is the one to be predicted\n",
    "print(\"INPUT DATA: \",df_input.shape)\n",
    "print(\"TEST  DATA: \",df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210a6f36",
   "metadata": {},
   "source": [
    "TRAINING AND MODEL SELECTION (DECISION TREE/SIMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad18281",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_input.drop(columns=[\"income\"])\n",
    "Y = df_input[\"income\"]\n",
    "\n",
    "#Creation of 4 validation sets \n",
    "kfold = KFold(n_splits=4,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d000aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL 1 ==> gini (default)\n",
    "# model1 = DecisionTreeClassifier(random_state=2)\n",
    "# score1 = []\n",
    "\n",
    "# #model training using 4 validation sets\n",
    "# for i in range(4):\n",
    "#     result = next(kfold.split(X),None)\n",
    "#     x_train = X.iloc[result[0]]\n",
    "#     x_test = X.iloc[result[1]]\n",
    "#     y_train = Y.iloc[result[0]]\n",
    "#     y_test = Y.iloc[result[1]]\n",
    "#     model1.fit(x_train,y_train)\n",
    "#     prediction1 = model1.predict(x_test)\n",
    "#     score1.append(accuracy_score(y_test,prediction1))\n",
    "\n",
    "# print(\"VALIDATION SET MISSCLASSIFICATION %.2f%%\" % ((1-np.mean(score1))*100))\n",
    "# MISSCLASSIFICATION ≈ 23.84%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae6ae81",
   "metadata": {},
   "source": [
    "TRAINING AND MODEL SELECTION (DECISION TREE/HYPERAMETER TWEAKING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddc3922",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: DecisionTreeClassifier DOESN'T have a min_leaf_size\n",
    "#parameter, the closes thing is min_samples_split\n",
    "\n",
    "#MODEL 2 ==> entropy \n",
    "# model2 = DecisionTreeClassifier(criterion=\"entropy\",random_state=2)\n",
    "# score2 = []\n",
    "\n",
    "# for i in range(4):\n",
    "#     result = next(kfold.split(X),None)\n",
    "#     x_train = X.iloc[result[0]]\n",
    "#     x_test = X.iloc[result[1]]\n",
    "#     y_train = Y.iloc[result[0]]\n",
    "#     y_test = Y.iloc[result[1]]\n",
    "#     model2.fit(x_train,y_train)\n",
    "#     prediction2 = model2.predict(x_test)\n",
    "#     score2.append(accuracy_score(y_test,prediction2))\n",
    "\n",
    "# print(\"VALIDATION SET MISSCLASSIFICATION %.2f%%\" % ((1-np.mean(score2))*100))\n",
    "#MISSCLASSIFICATION ≈ 23.9%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc569ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL 3 ==> entropy + min-samples_splot = 5\n",
    "# model3 = DecisionTreeClassifier(criterion=\"entropy\",splitter=\"best\",random_state=2,min_samples_split=5)\n",
    "# score3 = []\n",
    "\n",
    "# for i in range(4):\n",
    "#     result = next(kfold.split(X),None)\n",
    "#     x_train = X.iloc[result[0]]\n",
    "#     x_test = X.iloc[result[1]]\n",
    "#     y_train = Y.iloc[result[0]]\n",
    "#     y_test = Y.iloc[result[1]]\n",
    "#     model3.fit(x_train,y_train)\n",
    "#     prediction3 = model3.predict(x_test)\n",
    "#     score3.append(accuracy_score(y_test,prediction3))\n",
    "\n",
    "# print(\"VALIDATION SET MISSCLASSIFICATION %.2f%%\" % ((1-np.mean(score3))*100))\n",
    "#MISSCLASSIFICATION ≈ 23.7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b93a57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL 4 ==> gini + min-samples_splot = 7\n",
    "# model4 = DecisionTreeClassifier(criterion=\"gini\",splitter=\"best\",random_state=2,min_samples_split=7)\n",
    "# score4 = []\n",
    "\n",
    "# for i in range(4):\n",
    "#     result = next(kfold.split(X),None)\n",
    "#     x_train = X.iloc[result[0]]\n",
    "#     x_test = X.iloc[result[1]]\n",
    "#     y_train = Y.iloc[result[0]]\n",
    "#     y_test = Y.iloc[result[1]]\n",
    "#     model4.fit(x_train,y_train)\n",
    "#     prediction4 = model4.predict(x_test)\n",
    "#     score4.append(accuracy_score(y_test,prediction4))\n",
    "\n",
    "# print(\"VALIDATION SET MISSCLASSIFICATION %.2f%%\" % ((1-np.mean(score4))*100))\n",
    "#MISSCLASSIFICATION ≈ 23.4%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e30e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL 5 ==> entropy + + min-samples_splot = 10\n",
    "# model5 = DecisionTreeClassifier(criterion=\"entropy\",splitter=\"best\",random_state=2,min_samples_split=10)\n",
    "# score5 = []\n",
    "\n",
    "# for i in range(4):\n",
    "#     result = next(kfold.split(X),None)\n",
    "#     x_train = X.iloc[result[0]]\n",
    "#     x_test = X.iloc[result[1]]\n",
    "#     y_train = Y.iloc[result[0]]\n",
    "#     y_test = Y.iloc[result[1]]\n",
    "#     model5.fit(x_train,y_train)\n",
    "#     prediction5 = model5.predict(x_test)\n",
    "#     score5.append(accuracy_score(y_test,prediction5))\n",
    "\n",
    "# print(\"VALIDATION SET MISSCLASSIFICATION %.2f%%\" % ((1-np.mean(score5))*100))\n",
    "#MISSCLASSIFICATION ≈ 23.3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03cad96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL  ==> entropy + + min-samples_splot = 50\n",
    "# model6 = DecisionTreeClassifier(criterion=\"entropy\",splitter=\"best\",random_state=2,min_samples_split=50)\n",
    "# score6 = []\n",
    "\n",
    "# for i in range(4):\n",
    "#     result = next(kfold.split(X),None)\n",
    "#     x_train = X.iloc[result[0]]\n",
    "#     x_test = X.iloc[result[1]]\n",
    "#     y_train = Y.iloc[result[0]]\n",
    "#     y_test = Y.iloc[result[1]]\n",
    "#     model6.fit(x_train,y_train)\n",
    "#     prediction6 = model6.predict(x_test)\n",
    "#     score6.append(accuracy_score(y_test,prediction6))\n",
    "\n",
    "# print(\"VALIDATION SET MISSCLASSIFICATION %.2f%%\" % ((1-np.mean(score6))*100))\n",
    "# #MISSCLASSIFICATION ≈ 21.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccda6bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL 7 ==> entropy + + min-samples_splot = 100 \n",
    "model7 = DecisionTreeClassifier(criterion=\"entropy\",splitter=\"best\",random_state=2,min_samples_split=100)\n",
    "score7 = []\n",
    "\n",
    "for i in range(4):\n",
    "    result = next(kfold.split(X),None)\n",
    "    x_train = X.iloc[result[0]]\n",
    "    x_test = X.iloc[result[1]]\n",
    "    y_train = Y.iloc[result[0]]\n",
    "    y_test = Y.iloc[result[1]]\n",
    "    model7.fit(x_train,y_train)\n",
    "    prediction7 = model7.predict(x_test)\n",
    "    score7.append(accuracy_score(y_test,prediction7))\n",
    "\n",
    "#print(\"VALIDATION SET MISSCLASSIFICATION %.2f%%\" % ((1-np.mean(score7))*100))\n",
    "#MISSCLASSIFICATION ≈ 20.3% --=>BEST PERFORMANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21861f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL 8 ==> entropy + + min-samples_splot = 300 \n",
    "# model8 = DecisionTreeClassifier(criterion=\"entropy\",splitter=\"best\",random_state=2,min_samples_split=300)\n",
    "# score8 = []\n",
    "\n",
    "# for i in range(4):\n",
    "#     result = next(kfold.split(X),None)\n",
    "#     x_train = X.iloc[result[0]]\n",
    "#     x_test = X.iloc[result[1]]\n",
    "#     y_train = Y.iloc[result[0]]\n",
    "#     y_test = Y.iloc[result[1]]\n",
    "#     model8.fit(x_train,y_train)\n",
    "#     prediction8 = model8.predict(x_test)\n",
    "#     score8.append(accuracy_score(y_test,prediction8))\n",
    "\n",
    "# print(\"VALIDATION SET MISSCLASSIFICATION %.2f%%\" % ((1-np.mean(score8))*100))\n",
    "# MISSCLASSIFICATION ≈ 21.1% "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2012114",
   "metadata": {},
   "source": [
    "MODEL EVALUATION (OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06816ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print model accuracy\n",
    "print(\"MODEL ACCURACY %.2f%%\" % ((np.mean(score7))*100))\n",
    "\n",
    "#output of classification report of a random sample\n",
    "#because the model was using cross validiton\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.25,random_state=2)\n",
    "predictions_set = model7.predict(X_test)\n",
    "target_names = [\"<=50\",\">50\"]\n",
    "print(\"CLASSIFICATION REPORT\\n\",classification_report(Y_test, predictions_set,target_names=target_names))\n",
    "\n",
    "#Predict the test data, and creating a csv file\n",
    "predictions_test = model7.predict(df_test)\n",
    "np.savetxt('pred_dt_2.csv',predictions_test,fmt='%.0d',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f14d216",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction visulizations\n",
    "performance = {'performance':[23.84,23.9,23.7,23.4,23.3,21.5,20.3,21.1]}\n",
    "performance_df = pd.DataFrame(data=performance)\n",
    "performance_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
